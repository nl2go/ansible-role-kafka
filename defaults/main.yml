---
kafka_apache_mirror_base_url: https://mirror.netcologne.de/apache.org

kafka_user: kafka
kafka_group: kafka

kafka_version: 2.5.0
kafka_scala_version: 2.12
kafka_broker_id: 1 # must be set to a unique integer for each broker

kafka_install_dir: /usr/local/kafka
kafka_conf_dir: /etc/kafka
kafka_data_dir: /var/lib/kafka
kafka_log_dir: /var/log/kafka

kafka_host: "{{ ansible_default_ipv4.address }}"
############################# Basic Kafka Settings

# The number of threads that the server uses for receiving requests from the network and sending responses to the network
kafka_num_network_threads: 3

# The number of threads that the server uses for processing requests, which may include disk I/O
kafka_num_io_threads: 8

# The send buffer (SO_SNDBUF) used by the socket server
kafka_socket_send_buffer_bytes: 102400

# The receive buffer (SO_RCVBUF) used by the socket server
kafka_socket_receive_buffer_bytes: 102400

# The maximum size of a request that the socket server will accept (protection against OOM)
kafka_socket_request_max_bytes: 104857600

### OPTIONAL config settings for kafka

# The address the socket server listens on. It will get the value returned from
# java.net.InetAddress.getCanonicalHostName() if not configured.
#   FORMAT:
#     listener_name://host_name:port
#   EXAMPLE:
#     PLAINTEXT://your.host.name:9092
# kafka_listeners: "PLAINTEXT://:9092"

# Hostname and port the broker will advertise to producers and consumers. If not set,
# it uses the value for "listeners" if configured.  Otherwise, it will use the value
# returned from java.net.InetAddress.getCanonicalHostName().
# kafka_advertised_listeners: "PLAINTEXT://{{ ansible_default_ipv4.address }}:9092"

# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details
#kafka_listener_security_protocol_map: "PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL"

# Additional optional security and sasl related settings
#security.inter.broker.protocol=PLAINTEXT
#sasl.mechanism.inter.broker.protocol=PLAIN
#sasl.enabled.mechanisms=PLAIN

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
kafka_num_partitions: 1

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
kafka_num_recovery_threads_per_data_dir: 1

############################# Internal Topic Settings

# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.
kafka_offsets_topic_replication_factor: 1
kafka_transaction_state_log_replication_factor: 1
kafka_transaction_state_log_min_isr: 1

############################# Log Flush Policy

# The number of messages to accept before forcing a flush of data to disk
kafka_log_flush_interval_messages: 10000

# The maximum amount of time a message can sit in a log before we force a flush
kafka_log_flush_interval_ms: 1000

############################# Log Retention Policy

# The minimum age of a log file to be eligible for deletion due to age
kafka_log_retention_hours: 168

# A size-based retention policy for logs. Segments are pruned from the log unless the remaining
# segments drop below log.retention.bytes. Functions independently of log.retention.hours.
kafka_log_retention_bytes: 1073741824

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
kafka_log_segment_bytes: 1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
kafka_log_retention_check_interval_ms: 300000

############################# Zookeeper related Kafka settings

kafka_zookeeper_connection_hosts:
  - localhost:2181

# Timeout in ms for connecting to zookeeper
kafka_zookeeper_connection_timeout_ms: 18000

# ZooKeeper SASL authentication
kafka_zookeeper_user: bar
kafka_zookeeper_password: baz

############################# Group Coordinator Settings

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
kafka_group_initial_rebalance_delay_ms: 0

############################# Kafka environment variables

# Kafka leverages a lot of environment variables to control JVM settings, logging options, monitoring options, etc..
# In order to set these variables for the kafka service use the optional 'kafka_environment_variables' setting.
# When defined the respective variables will be written to an env file which will be used in the EnvironmentFile setting of the systemd service.
#
# Sample file content for configuring KAFKA_HEAP_OPTS:
# KAFKA_HEAP_OPTS="-Xmx192M"
#
# An overview of the variables used by kafka can be found in the kafka startup script here: https://github.com/apache/kafka/blob/trunk/bin/kafka-run-class.sh
kafka_environment_variables: {}

# Environment file that will be created by the role and used in the Kafka systemd service definition if kafka_environment_variables is defined
kafka_environment_file: /etc/kafka/kafka.env

kafka_server_username: broker
kafka_server_password: broker
kafka_client_users:
  - username: guest
    password: guest

# JMX related settings
kafka_jmx_enabled: false
kafka_jmx_host: localhost
kafka_jmx_port: 1099
kafka_jmx_rmi_port: 1099
kafka_jmx_role: readonly
# Optional settings for using authentication
# kafka_jmx_username: jmx
# kafka_jmx_password: jmx
